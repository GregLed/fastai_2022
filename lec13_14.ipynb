{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ntUlTY5Jl8_F"
      },
      "outputs": [],
      "source": [
        "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from torch import tensor,nn\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import test_close\n",
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "torch.manual_seed(1)\n",
        "mpl.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ezYsGR0v7rkC"
      },
      "outputs": [],
      "source": [
        "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True)\n",
        "path_gz = path_data/'mnist.pkl.gz'\n",
        "\n",
        "\n",
        "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x1jAoouV7TCG"
      },
      "outputs": [],
      "source": [
        "with gzip.open(path_gz, 'rb') as f:\n",
        "     ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfC6j_Ha8LMP"
      },
      "source": [
        "# Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20bYFPWg7i--",
        "outputId": "e01d6362-5e54-4f06-9880-4cc85326b7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000 784\n"
          ]
        }
      ],
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50\n",
        "\n",
        "print(n, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9MlF7E9o8Pao"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ATkEg_a8UKJ",
        "outputId": "184aae34-6e45-4967-fdc2-7c7582e408cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0By57x9-LQG"
      },
      "source": [
        "# Cross entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxE4a_oG-P-I",
        "outputId": "e0e1a3b1-75d2-453d-a3e1-e0df61ef02c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.exp().sum(axis=-1, keepdim=True).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFKN31E8-PAm",
        "outputId": "1c8c7869-e742-4ffd-f961-3f883ddaec94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prob = (pred.exp() / pred.exp().sum(axis=-1, keepdim=True))\n",
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OFvztwxhDQFn"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S46QTM_ODqxY"
      },
      "outputs": [],
      "source": [
        "# we can use logarithm property to split division into deduction\n",
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1,keepdim=True).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3G3YIgixD5b-"
      },
      "outputs": [],
      "source": [
        "# denominator can be problematic because of floating numbers are not stable\n",
        "# for big numbers. We can find max for each row and deduct it from other vals\n",
        "def logsumexp(x):\n",
        "    m = x.max(-1).values\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePNgYRBjFXh2",
        "outputId": "e743c0c6-5b1b-428a-d084-f74ffce4b6e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.10, 0.14, 0.21,  ..., 0.14, 0.11, 0.14], grad_fn=<MaxBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.max(-1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LCfZUPEpFYAN"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.logsumexp(-1,keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ijBkaZOFnhy",
        "outputId": "d6ddcf84-a93d-4ec4-cc4f-8478ea9546a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
              "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
              "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
              "        ...,\n",
              "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
              "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
              "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
        "log_sm_pred = log_softmax(pred)\n",
        "log_sm_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbAglCqqdQZB"
      },
      "source": [
        "# Cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk2zR-oadmYv",
        "outputId": "754731d1-20e2-4d5b-93d6-d1b1a4b94fbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "-log_sm_pred[range(y_train.shape[0]), y_train].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1pPhhC6FpYW",
        "outputId": "c3e79a57-c1a5-458b-ad72-c61106613e52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that original math formula uses sum and we use mean to conrol the scale.\n",
        "# Mathematically both have the same max or min and sum is just divided by a\n",
        "# constant which is n-examples (targets.shape[0])\n",
        "def nll(log_prob, targets):\n",
        "    return -log_prob[range(targets.shape[0]), targets].mean()\n",
        "\n",
        "loss = nll(log_sm_pred, y_train)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "leFJqXBvd8cW"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation\n",
        "# Note that nll_loss takes as input log probabilities and cross_entropy just model outputs\n",
        "\n",
        "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)\n",
        "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfR7za1wk7-q"
      },
      "source": [
        "# Basic training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oIhaec5Qks2U"
      },
      "outputs": [],
      "source": [
        "loss_func = F.cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I06YPG11k-mv",
        "outputId": "882f1958-d81d-4238-c8e5-a44f428152e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.20,  0.04,  0.06, -0.06, -0.05,  0.08, -0.10,  0.15, -0.05, -0.03], grad_fn=<SelectBackward0>),\n",
              " torch.Size([500, 10]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bs=500                  # batch size\n",
        "lr = 0.5               # learning rate\n",
        "epochs = 3             # how many epochs to train for\n",
        "n = y_train.shape[0]\n",
        "\n",
        "xb = x_train[0:bs]     # a mini-batch from x\n",
        "yb = y_train[0:bs]\n",
        "\n",
        "preds = model(xb)      # predictions\n",
        "preds[0], preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJk-pFBlDoO",
        "outputId": "efe9d272-e46c-4eba-e1e7-aee048db561b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.31, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_func(preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOQyrAGGlJQf",
        "outputId": "c7626661-f51e-49bf-d07a-d937916eaa3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 7, 7, 7, 5, 7, 0, 7, 5, 7, 0, 7, 7, 5, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 0, 7, 5, 7, 5, 7, 7, 7, 5, 7, 7, 7, 0, 7, 0, 5, 5, 0, 5, 5,\n",
              "        0, 5, 0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 5, 7, 5, 5, 0, 7, 0, 7, 5, 7, 7, 7, 0, 5, 7, 7, 7, 7,\n",
              "        7, 5, 5, 7, 7, 5, 5, 7, 5, 0, 0, 5, 0, 7, 5, 7, 5, 5, 0, 7, 7, 5, 7, 7, 5, 5, 7, 5, 5, 0, 5, 7, 7, 7, 9, 7, 5, 0, 5, 7, 5, 0, 7, 7,\n",
              "        5, 5, 7, 0, 0, 7, 0, 5, 5, 7, 5, 7, 5, 5, 0, 5, 5, 7, 5, 5, 5, 7, 7, 5, 7, 7, 5, 7, 5, 0, 0, 5, 7, 5, 5, 7, 5, 0, 5, 7, 7, 7, 5, 5,\n",
              "        0, 5, 7, 7, 5, 7, 5, 5, 5, 7, 5, 0, 0, 7, 7, 5, 7, 7, 7, 7, 7, 7, 5, 7, 0, 7, 0, 7, 5, 7, 7, 7, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7,\n",
              "        7, 5, 7, 7, 7, 7, 5, 5, 0, 7, 7, 5, 7, 7, 5, 7, 5, 5, 5, 7, 0, 5, 7, 7, 5, 7, 7, 5, 0, 7, 7, 5, 0, 5, 7, 0, 5, 5, 0, 7, 7, 5, 5, 7,\n",
              "        5, 0, 0, 5, 5, 5, 7, 5, 7, 7, 0, 5, 5, 5, 0, 7, 5, 7, 7, 7, 7, 5, 5, 7, 0, 5, 5, 0, 5, 7, 7, 0, 7, 5, 0, 5, 0, 7, 0, 7, 0, 7, 7, 7,\n",
              "        7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 7, 5, 7, 7, 5, 5, 7, 7, 5, 0, 5, 7, 5, 0, 7, 5, 7, 5, 7, 5, 7, 0, 7, 5, 0, 7, 5, 7, 5, 7, 7, 5, 5,\n",
              "        5, 7, 5, 7, 7, 5, 5, 7, 5, 7, 0, 5, 5, 5, 5, 5, 0, 5, 5, 7, 5, 5, 5, 7, 0, 7, 5, 5, 7, 7, 5, 5, 5, 7, 7, 7, 5, 0, 7, 7, 7, 5, 7, 5,\n",
              "        7, 5, 5, 7, 5, 5, 5, 0, 0, 7, 0, 7, 0, 0, 5, 7, 5, 5, 5, 7, 5, 5, 7, 0, 0, 5, 7, 0, 5, 7, 7, 7, 0, 7, 7, 5, 0, 7, 7, 7, 7, 7, 5, 7,\n",
              "        7, 0, 5, 5, 5, 0, 7, 5, 5, 5, 5, 5, 7, 7, 5, 7, 7, 5, 5, 7, 7, 5, 7, 5, 7, 5, 7, 7, 7, 7, 0, 7, 5, 7, 7, 7, 5, 7, 5, 0, 5, 7, 5, 5,\n",
              "        5, 5, 0, 7, 5, 5, 5, 7, 7, 7, 5, 7, 0, 7, 5, 0])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To get prediction for each example we can use argmax across columns\n",
        "preds.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzarbeR-lPne",
        "outputId": "8151b4d7-911b-4d39-cd27-9247531ffd46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.10)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()\n",
        "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')\n",
        "\n",
        "accuracy(preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouqvO_Mglgyx",
        "outputId": "ff521a4b-7180-4e55-b4da-59b3bfbfa5ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.31, 0.10\n"
          ]
        }
      ],
      "source": [
        "report(loss_func(preds, yb), preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUQowvMVliu3",
        "outputId": "77910385-fcf4-4d18-9ef1-63118809387e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 29.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45, 0.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 36.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.38, 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 36.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.32, 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = Model(m, nh, 10)\n",
        "\n",
        "for j in range(epochs):\n",
        "    for i in tqdm(range(0, n, bs)):\n",
        "        # get slice of data\n",
        "        s = slice(i, min(i+bs,n))\n",
        "        xb = x_train[s]\n",
        "        yb = y_train[s]\n",
        "\n",
        "        # calculate predictions, loss and gradients\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights of the model\n",
        "        with torch.no_grad():\n",
        "            for layer in model.layers:\n",
        "                if hasattr(layer, 'weight'):\n",
        "                    layer.weight -= lr * layer.weight.grad\n",
        "                    layer.bias -= lr * layer.bias.grad\n",
        "                    layer.weight.grad.zero_()\n",
        "                    layer.bias.grad.zero_()\n",
        "\n",
        "    report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJci0CIm3NoJ",
        "outputId": "1792368b-1d8b-4cca-f6cb-fd673fd1e657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([500, 10])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simplify model\n",
        "\n",
        "1) Running a few layers in a row is very common so there is a class in pytroch to simplify it, nn.Sequential\n",
        "2) Rather than checking if a layer has weight attribute, we can use .parameters() method to loop over all params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_out = 10 # we have 10 digit classes to predict\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: Linear(in_features=784, out_features=50, bias=True)\n",
            "1: ReLU()\n",
            "2: Linear(in_features=50, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "for nm, module in model.named_children():\n",
        "    print(f\"{nm}: {module}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# we have to Linear layers and each has weights and biases as parameters\n",
        "\n",
        "for p in model.parameters():\n",
        "    print(p.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for i in tqdm(range(0, n, bs)):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb = x_train[s]\n",
        "            yb = y_train[s]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "                \n",
        "        report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 16.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45, 0.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 16.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.35, 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 16.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.30, 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Refactoring weights update to the Optimizer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5):\n",
        "        self.params = list(params) # convert a generator to a list\n",
        "        self.lr = lr\n",
        "    \n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params:\n",
        "                p -= p.grad * self.lr\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        for p in self.params:\n",
        "            p.grad.data.zero_() # with .data we don't need to use no_grad context mgmt    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "opt = Optimizer(model.parameters(), lr=0.5)\n",
        "\n",
        "def fit():\n",
        "    for _ in range(epochs):\n",
        "        for i in tqdm(range(0, n, bs)):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb, yb = x_train[s], y_train[s]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:08<00:00, 11.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.44, 0.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:08<00:00, 11.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.34, 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:08<00:00, 11.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.29, 0.92\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Put model and data on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "model.to(device)\n",
        "\n",
        "opt = Optimizer(model.parameters())\n",
        "\n",
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for i in range(0, n, bs):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb, yb = x_train[s].to(device), y_train[s].to(device)\n",
        "            pred = model(xb.to(device))\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        if  j % 10==0: report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.43, 0.89\n",
            "0.15, 0.96\n",
            "0.09, 0.97\n",
            "0.06, 0.98\n",
            "0.04, 0.99\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset class\n",
        "we want to abstract iterating over x and y into one class. We need to define two dunder methods: len and getitem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "    def __init__(self, x, y) -> None:\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.x[i], self.y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "model.to(device)\n",
        "\n",
        "opt = Optimizer(model.parameters())\n",
        "\n",
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for i in range(0, n, bs):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb, yb = train_ds[s]\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        if  j % 10==0: report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.46, 0.88\n",
            "0.15, 0.96\n",
            "0.10, 0.97\n",
            "0.06, 0.98\n",
            "0.04, 0.99\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHo9FFK5uM0m"
      },
      "source": [
        "# DataLoader\n",
        "\n",
        "We want to one get read of setting up slice in the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Dataloader:\n",
        "    def __init__(self, ds, bs):\n",
        "        self.ds = ds\n",
        "        self.bs = bs\n",
        "        self.n = len(self.ds)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for i in range(0, self.n , bs): \n",
        "            yield self.ds[i:min(i+self.bs, self.n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "dl = Dataloader(train_ds, bs)\n",
        "\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out)).to(device)\n",
        "opt = Optimizer(model.parameters())\n",
        "\n",
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for xb, yb in dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        if  j % 10==0: report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.44, 0.88\n",
            "0.14, 0.95\n",
            "0.08, 0.97\n",
            "0.05, 0.98\n",
            "0.04, 0.99\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sampler\n",
        "\n",
        "We want to now randomize the order of our observations in each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from itertools import islice\n",
        "\n",
        "class Sampler:\n",
        "    def __init__(self, n, shuffle=False):\n",
        "        self.n = n\n",
        "        self.shuffle = shuffle\n",
        "    \n",
        "    def __iter__(self):\n",
        "        res = list(range(self.n))\n",
        "        if self.shuffle:\n",
        "            random.shuffle(res)\n",
        "        return iter(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = Sampler(len(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "for i in s:\n",
        "    print(i)\n",
        "    if i == 5: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(islice(s, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[44362, 33795, 37268, 29537, 49926]"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss = Sampler(len(train_ds), shuffle=True)\n",
        "list(islice(ss, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fastcore.all as fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BatchSampler():\n",
        "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
        "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[8960, 29371, 17473, 40917],\n",
              " [49215, 12854, 24563, 16384],\n",
              " [26683, 18202, 1741, 41649],\n",
              " [1684, 17683, 2222, 11707],\n",
              " [43431, 40794, 33962, 631]]"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batchs = BatchSampler(ss, 4)\n",
        "list(islice(batchs, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "4Da2qQraul-D"
      },
      "outputs": [],
      "source": [
        "a = [(1,2), (3,4), (5,6), (7,8)]\n",
        "x, y = zip(*a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwkQIAOBu3hD",
        "outputId": "c504b102-bcdc-4501-d76c-8005c082b9bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 3, 5, 7), (2, 4, 6, 8))"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POio2Dx5yUAY",
        "outputId": "45ca344b-ffa6-48a1-88a9-5c07f4b57861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(1), tensor(3), tensor(5), tensor(7)]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [torch.tensor(i) for i in x]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBjc_Zmu4Bk",
        "outputId": "cf966a31-bf5e-4639-aaf1-80d864e0db19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 3, 5, 7])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.stack(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbsOxxadzSGe"
      },
      "source": [
        "# zip vs zip_longest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn_r0wEoyF2U",
        "outputId": "8600c938-a8ba-4cf8-c875-16b844259836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 5), (2, 6), (3, 7)]\n",
            "[(1, 5), (2, 6), (3, 7), (4, None)]\n"
          ]
        }
      ],
      "source": [
        "from itertools import zip_longest\n",
        "\n",
        "a = (1,2,3,4)\n",
        "b = (5,6,7)\n",
        "\n",
        "print(list(zip(a,b)))\n",
        "print(list(zip_longest(a, b)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79oXKGAEzkU2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPl8+OyfvrGSLLFPm1n/53W",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
