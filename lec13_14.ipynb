{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ntUlTY5Jl8_F"
      },
      "outputs": [],
      "source": [
        "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from torch import tensor,nn\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import test_close\n",
        "import fastcore.all as fc\n",
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "torch.manual_seed(1)\n",
        "mpl.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ezYsGR0v7rkC"
      },
      "outputs": [],
      "source": [
        "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True)\n",
        "path_gz = path_data/'mnist.pkl.gz'\n",
        "\n",
        "\n",
        "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x1jAoouV7TCG"
      },
      "outputs": [],
      "source": [
        "with gzip.open(path_gz, 'rb') as f:\n",
        "     ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfC6j_Ha8LMP"
      },
      "source": [
        "# Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20bYFPWg7i--",
        "outputId": "e01d6362-5e54-4f06-9880-4cc85326b7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000 784\n"
          ]
        }
      ],
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50\n",
        "\n",
        "print(n, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9MlF7E9o8Pao"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ATkEg_a8UKJ",
        "outputId": "184aae34-6e45-4967-fdc2-7c7582e408cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0By57x9-LQG"
      },
      "source": [
        "# Cross entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxE4a_oG-P-I",
        "outputId": "e0e1a3b1-75d2-453d-a3e1-e0df61ef02c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.exp().sum(axis=-1, keepdim=True).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFKN31E8-PAm",
        "outputId": "1c8c7869-e742-4ffd-f961-3f883ddaec94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prob = (pred.exp() / pred.exp().sum(axis=-1, keepdim=True))\n",
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OFvztwxhDQFn"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "S46QTM_ODqxY"
      },
      "outputs": [],
      "source": [
        "# we can use logarithm property to split division into deduction\n",
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1,keepdim=True).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3G3YIgixD5b-"
      },
      "outputs": [],
      "source": [
        "# denominator can be problematic because of floating numbers are not stable\n",
        "# for big numbers. We can find max for each row and deduct it from other vals\n",
        "def logsumexp(x):\n",
        "    m = x.max(-1).values\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePNgYRBjFXh2",
        "outputId": "e743c0c6-5b1b-428a-d084-f74ffce4b6e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.10, 0.14, 0.21,  ..., 0.14, 0.11, 0.14], grad_fn=<MaxBackward0>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.max(-1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LCfZUPEpFYAN"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.logsumexp(-1,keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ijBkaZOFnhy",
        "outputId": "d6ddcf84-a93d-4ec4-cc4f-8478ea9546a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
              "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
              "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
              "        ...,\n",
              "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
              "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
              "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
        "log_sm_pred = log_softmax(pred)\n",
        "log_sm_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbAglCqqdQZB"
      },
      "source": [
        "# Cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk2zR-oadmYv",
        "outputId": "754731d1-20e2-4d5b-93d6-d1b1a4b94fbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "-log_sm_pred[range(y_train.shape[0]), y_train].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1pPhhC6FpYW",
        "outputId": "c3e79a57-c1a5-458b-ad72-c61106613e52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that original math formula uses sum and we use mean to conrol the scale.\n",
        "# Mathematically both have the same max or min and sum is just divided by a\n",
        "# constant which is n-examples (targets.shape[0])\n",
        "def nll(log_prob, targets):\n",
        "    return -log_prob[range(targets.shape[0]), targets].mean()\n",
        "\n",
        "loss = nll(log_sm_pred, y_train)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "leFJqXBvd8cW"
      },
      "outputs": [],
      "source": [
        "# Pytorch implementation\n",
        "# Note that nll_loss takes as input log probabilities and cross_entropy just model outputs\n",
        "\n",
        "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)\n",
        "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfR7za1wk7-q"
      },
      "source": [
        "# Basic training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oIhaec5Qks2U"
      },
      "outputs": [],
      "source": [
        "loss_func = F.cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I06YPG11k-mv",
        "outputId": "882f1958-d81d-4238-c8e5-a44f428152e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>),\n",
              " torch.Size([500, 10]))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bs=500                  # batch size\n",
        "lr = 0.5               # learning rate\n",
        "epochs = 3             # how many epochs to train for\n",
        "n = y_train.shape[0]\n",
        "\n",
        "xb = x_train[0:bs]     # a mini-batch from x\n",
        "yb = y_train[0:bs]\n",
        "\n",
        "preds = model(xb)      # predictions\n",
        "preds[0], preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJk-pFBlDoO",
        "outputId": "efe9d272-e46c-4eba-e1e7-aee048db561b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.31, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_func(preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOQyrAGGlJQf",
        "outputId": "c7626661-f51e-49bf-d07a-d937916eaa3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n",
              "        3, 5, 9, 5, 9, 5, 3, 9, 3, 8, 9, 5, 9, 5, 9, 5, 8, 8, 9, 8, 8, 3, 9, 3, 3, 9, 3, 9, 3, 3, 9, 9, 3, 8, 4, 3, 3, 9, 9, 3, 3, 9, 3, 9,\n",
              "        8, 9, 9, 9, 9, 3, 9, 9, 5, 5, 3, 3, 9, 3, 3, 8, 3, 3, 9, 5, 6, 3, 5, 5, 3, 3, 9, 9, 5, 9, 9, 5, 3, 9, 4, 9, 3, 9, 9, 9, 3, 9, 5, 9,\n",
              "        9, 5, 8, 9, 9, 5, 9, 9, 4, 3, 3, 8, 9, 9, 9, 9, 9, 3, 3, 9, 3, 5, 9, 9, 3, 5, 8, 9, 3, 5, 9, 5, 9, 3, 9, 9, 5, 9, 5, 5, 9, 4, 3, 9,\n",
              "        9, 3, 3, 5, 3, 5, 3, 5, 3, 9, 3, 9, 9, 9, 9, 9, 9, 9, 9, 8, 9, 9, 9, 5, 3, 3, 5, 5, 9, 3, 9, 5, 3, 8, 9, 3, 9, 9, 3, 3, 9, 5, 3, 5,\n",
              "        9, 9, 3, 9, 5, 9, 9, 9, 9, 8, 7, 3, 3, 9, 9, 3, 5, 5, 9, 5, 3, 9, 5, 9, 9, 5, 8, 9, 3, 8, 9, 3, 3, 9, 8, 9, 9, 5, 3, 9, 9, 9, 9, 9,\n",
              "        9, 9, 9, 9, 3, 3, 3, 5, 9, 9, 9, 9, 3, 9, 9, 3, 5, 5, 8, 9, 8, 9, 9, 9, 8, 9, 3, 9, 5, 9, 9, 5, 9, 5, 9, 9, 5, 9, 9, 9, 3, 7, 8, 7,\n",
              "        9, 3, 3, 9, 9, 5, 3, 3, 3, 9, 8, 9, 9, 5, 3, 9, 3, 9, 8, 5, 9, 3, 5, 9, 9, 9, 3, 9, 5, 9, 3, 9, 9, 3, 9, 5, 9, 3, 9, 9, 5, 9, 9, 4,\n",
              "        9, 5, 3, 3, 5, 3, 3, 5, 9, 5, 9, 5, 3, 9, 3, 9, 3, 5, 3, 5, 3, 3, 9, 9, 9, 9, 9, 3, 3, 9, 3, 9, 3, 5, 3, 7, 3, 9, 5, 9, 5, 9, 3, 9,\n",
              "        9, 3, 3, 9, 9, 9, 9, 5, 8, 3, 3, 5, 3, 5, 3, 7, 3, 5, 9, 9, 3, 9, 3, 9, 3, 9, 3, 8, 9, 3, 3, 9, 9, 9, 9, 9, 3, 3, 3, 9, 9, 9, 9, 5,\n",
              "        9, 5, 3, 3, 3, 9, 8, 3, 4, 9, 3, 9, 8, 9, 3, 3, 3, 9, 9, 5, 9, 3, 9, 9, 9, 9, 3, 3, 8, 5, 8, 9, 3, 9, 9, 3, 9, 9, 8, 3, 9, 9, 5, 8,\n",
              "        3, 5, 9, 3, 3, 9, 9, 3, 5, 9, 9, 9, 5, 9, 9, 3])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To get prediction for each example we can use argmax across columns\n",
        "preds.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzarbeR-lPne",
        "outputId": "8151b4d7-911b-4d39-cd27-9247531ffd46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.11)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()\n",
        "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')\n",
        "\n",
        "accuracy(preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouqvO_Mglgyx",
        "outputId": "ff521a4b-7180-4e55-b4da-59b3bfbfa5ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.31, 0.11\n"
          ]
        }
      ],
      "source": [
        "report(loss_func(preds, yb), preds, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUQowvMVliu3",
        "outputId": "77910385-fcf4-4d18-9ef1-63118809387e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 3/100 [00:00<00:04, 22.30it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:05<00:00, 19.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45, 0.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:05<00:00, 19.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.36, 0.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 20.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.30, 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = Model(m, nh, 10)\n",
        "\n",
        "for j in range(epochs):\n",
        "    for i in tqdm(range(0, n, bs)):\n",
        "        # get slice of data\n",
        "        s = slice(i, min(i+bs,n))\n",
        "        xb = x_train[s]\n",
        "        yb = y_train[s]\n",
        "\n",
        "        # calculate predictions, loss and gradients\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights of the model\n",
        "        with torch.no_grad():\n",
        "            for layer in model.layers:\n",
        "                if hasattr(layer, 'weight'):\n",
        "                    layer.weight -= lr * layer.weight.grad\n",
        "                    layer.bias -= lr * layer.bias.grad\n",
        "                    layer.weight.grad.zero_()\n",
        "                    layer.bias.grad.zero_()\n",
        "\n",
        "    report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJci0CIm3NoJ",
        "outputId": "1792368b-1d8b-4cca-f6cb-fd673fd1e657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([500, 10])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simplify model\n",
        "\n",
        "1) Running a few layers in a row is very common so there is a class in pytroch to simplify it, nn.Sequential\n",
        "2) Rather than checking if a layer has weight attribute, we can use .parameters() method to loop over all params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_out = 10 # we have 10 digit classes to predict\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: Linear(in_features=784, out_features=50, bias=True)\n",
            "1: ReLU()\n",
            "2: Linear(in_features=50, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "for nm, module in model.named_children():\n",
        "    print(f\"{nm}: {module}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# we have to Linear layers and each has weights and biases as parameters\n",
        "\n",
        "for p in model.parameters():\n",
        "    print(p.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for i in tqdm(range(0, n, bs)):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb = x_train[s]\n",
        "            yb = y_train[s]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "                \n",
        "        report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:05<00:00, 17.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45, 0.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:07<00:00, 12.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.37, 0.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:05<00:00, 19.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.31, 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Refactoring weights update to the Optimizer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5):\n",
        "        self.params = list(params) # convert a generator to a list\n",
        "        self.lr = lr\n",
        "    \n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params:\n",
        "                p -= p.grad * self.lr\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        for p in self.params:\n",
        "            p.grad.data.zero_() # with .data we don't need to use no_grad context mgmt    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "opt = Optimizer(model.parameters(), lr=0.5)\n",
        "\n",
        "def fit():\n",
        "    for _ in range(epochs):\n",
        "        for i in tqdm(range(0, n, bs)):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb, yb = x_train[s], y_train[s]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 22.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.44, 0.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 22.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.36, 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:08<00:00, 11.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.31, 0.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Put model and data on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "model.to(device)\n",
        "\n",
        "opt = Optimizer(model.parameters())\n",
        "\n",
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for i in range(0, n, bs):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb, yb = x_train[s].to(device), y_train[s].to(device)\n",
        "            pred = model(xb.to(device))\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        if  j % 10==0: report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.46, 0.88\n",
            "0.14, 0.96\n",
            "0.08, 0.98\n",
            "0.05, 0.98\n",
            "0.04, 0.99\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset class\n",
        "we want to abstract iterating over x and y into one class. We need to define two dunder methods: len and getitem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "    def __init__(self, x, y) -> None:\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.x[i], self.y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out))\n",
        "model.to(device)\n",
        "\n",
        "opt = Optimizer(model.parameters())\n",
        "\n",
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for i in range(0, n, bs):\n",
        "            s = slice(i, min(i+bs,n))\n",
        "            xb, yb = train_ds[s]\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        if  j % 10==0: report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45, 0.88\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15, 0.96\n",
            "0.09, 0.98\n",
            "0.06, 0.98\n",
            "0.04, 0.99\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHo9FFK5uM0m"
      },
      "source": [
        "# DataLoader\n",
        "\n",
        "We want to one get read of setting up slice in the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Dataloader:\n",
        "    def __init__(self, ds, bs):\n",
        "        self.ds = ds\n",
        "        self.bs = bs\n",
        "        self.n = len(self.ds)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for i in range(0, self.n , bs): \n",
        "            yield self.ds[i:min(i+self.bs, self.n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "dl = Dataloader(train_ds, bs)\n",
        "\n",
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,n_out)).to(device)\n",
        "opt = Optimizer(model.parameters())\n",
        "\n",
        "def fit():\n",
        "    for j in range(epochs):\n",
        "        for xb, yb in dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        if  j % 10==0: report(loss, pred, yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.46, 0.88\n",
            "0.14, 0.96\n",
            "0.08, 0.98\n",
            "0.05, 0.99\n",
            "0.03, 0.99\n"
          ]
        }
      ],
      "source": [
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sampler\n",
        "\n",
        "We want to now randomize the order of our observations in each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from itertools import islice\n",
        "\n",
        "class Sampler:\n",
        "    def __init__(self, ds, shuffle=False):\n",
        "        self.n = len(ds)\n",
        "        self.shuffle = shuffle\n",
        "    \n",
        "    def __iter__(self):\n",
        "        res = list(range(self.n))\n",
        "        if self.shuffle:\n",
        "            random.shuffle(res)\n",
        "        return iter(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = Sampler(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "for i in s:\n",
        "    print(i)\n",
        "    if i == 5: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(islice(s, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[49733, 23313, 48567, 29316, 26738]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss = Sampler(train_ds, shuffle=True)\n",
        "list(islice(ss, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mSignature:\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSource:\u001b[0m   \n",
            "\u001b[0;32mdef\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Return batches from iterator `it` of size `chunk_sz` (or return `n_chunks` total)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32massert\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_sz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mn_chunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchunk_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mchunk_sz\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mchunk_sz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.10/dist-packages/fastcore/basics.py\n",
            "\u001b[0;31mType:\u001b[0m      function\n"
          ]
        }
      ],
      "source": [
        "fc.chunked??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[34703, 26589, 4507, 44615, 1778]\n",
            "[41945, 42784, 47195, 12830, 30495]\n"
          ]
        }
      ],
      "source": [
        "print(list(islice(ss,5)))\n",
        "print(list(islice(ss,5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The basic idea of this class is that we want to be able to chunk one iterator into batches\n",
        "\n",
        "class BatchSampler():\n",
        "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
        "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[45473, 29441, 14092, 38313],\n",
              " [2768, 21879, 7814, 26986],\n",
              " [16900, 7247, 43152, 31469],\n",
              " [4375, 8172, 32649, 35095],\n",
              " [33669, 36891, 22823, 49736]]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batchs = BatchSampler(ss, 4)\n",
        "list(islice(batchs, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 5), (2, 6), (3, 7)]\n",
            "[(1, 5), (2, 6), (3, 7), (4, None)]\n"
          ]
        }
      ],
      "source": [
        "from itertools import zip_longest\n",
        "\n",
        "a = (1,2,3,4)\n",
        "b = (5,6,7)\n",
        "\n",
        "print(list(zip(a,b)))\n",
        "print(list(zip_longest(a, b)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "4Da2qQraul-D"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 3, 5, 7), (2, 4, 6, 8))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [(1,2), (3,4), (5,6), (7,8)]\n",
        "x, y = zip(*a)\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POio2Dx5yUAY",
        "outputId": "45ca344b-ffa6-48a1-88a9-5c07f4b57861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(1), tensor(3), tensor(5), tensor(7)]\n",
            "tensor([1, 3, 5, 7])\n"
          ]
        }
      ],
      "source": [
        "xx = [torch.tensor(i) for i in x]\n",
        "print(xx)\n",
        "print(torch.stack(xx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBjc_Zmu4Bk",
        "outputId": "cf966a31-bf5e-4639-aaf1-80d864e0db19"
      },
      "outputs": [],
      "source": [
        "# We need a new DataLoader class because recall that Dataset returns a tuple of (x, y).\n",
        "# Now batch sampler gives us random indices for getting tuples of x and y and we want to \n",
        "# stack them together into just one tensor. That was not needed when we used a slice in \n",
        "# prior implementation because the slice was taking subsequent part of each tensor (x and y)\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
        "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "79oXKGAEzkU2"
      },
      "outputs": [],
      "source": [
        "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
        "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
        "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([500, 784]), torch.Size([500]))"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 500 pictures which are 28x28 (784 pixels in total) \n",
        "# and 500 corresponding labels \n",
        "\n",
        "xb.shape,yb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.44, 0.89\n",
            "0.15, 0.96\n",
            "0.09, 0.98\n",
            "0.06, 0.98\n",
            "0.05, 0.99\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multiprocessing DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.multiprocessing as mp\n",
        "from fastcore.basics import store_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPl8+OyfvrGSLLFPm1n/53W",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
